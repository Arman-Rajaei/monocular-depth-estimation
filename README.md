# Monocular Depth Estimation Using Deep Learning

This project demonstrates a simple Convolutional Neural Network (CNN) for monocular depth estimation using a small subset of the KITTI dataset.  
It is designed for fast experimentation, demonstration of 3D vision, and deep learning pipelines.

---

## ğŸš€ Project Structure

monocular-depth-estimation/ â”œâ”€â”€ data/ # Dataset folder (kept empty here; see below) â”œâ”€â”€ models/ â”‚ â””â”€â”€ depth_cnn.py # Simple CNN model for depth prediction â”œâ”€â”€ notebooks/ â”‚ â””â”€â”€ 01_load_data_and_visualize.ipynb # Data loading and training code â”œâ”€â”€ utils/ â”‚ â””â”€â”€ dataset.py # Custom PyTorch Dataset class â”œâ”€â”€ view_sample_image.py # Script to visualize images outside Jupyter â”œâ”€â”€ create_tiny_subset.py # Script to create a tiny dataset subset â”œâ”€â”€ requirements.txt # Python dependencies â”œâ”€â”€ README.md # Project description and instructions â””â”€â”€ .gitignore # Files to ignore when pushing to GitHub

---

## ğŸ“¥ How to Set Up

1. **Clone the repository:**
    ```bash
    git clone https://github.com/Arman-Rajaei/monocular-depth-estimation.git
    cd monocular-depth-estimation
    ```

2. **Install dependencies:**
    ```bash
    pip install -r requirements.txt
    ```

3. **Download KITTI sample dataset:**
    - Download a few images from the KITTI Raw Dataset (or use your own images).
    - Place them into the folder:
      ```
      data/kitti_tiny/training/image_2/
      ```
    - Make sure all images are resized automatically inside the code.

4. **(Optional)** Create a tiny subset using:
    ```bash
    python create_tiny_subset.py
    ```

---

## ğŸ‹ï¸ How to Train

- Open the Jupyter Notebook:
    ```bash
    jupyter notebook
    ```
- Navigate to:
    ```
    notebooks/01_load_data_and_visualize.ipynb
    ```
- Run the notebook to train the depth estimation model for a few epochs.

âœ… The model uses a lightweight CNN and L1 Loss to predict a grayscale depth map.

---

## ğŸ“ˆ Sample Results

- The model output is a single-channel depth map corresponding to input RGB images.
- Since this is a demonstration, the loss decreases steadily during training.

---

## ğŸ›  Future Improvements

- Train using real ground truth depth maps from KITTI.
- Improve model architecture with skip connections (e.g., U-Net structure).
- Test on larger datasets.
- Deploy lightweight model to mobile or embedded platforms.

---

## ğŸ“œ License

This project is open for personal and research usage.

---

## âœ¨ Acknowledgements

- [KITTI Dataset](http://www.cvlibs.net/datasets/kitti/)
- PyTorch Community
